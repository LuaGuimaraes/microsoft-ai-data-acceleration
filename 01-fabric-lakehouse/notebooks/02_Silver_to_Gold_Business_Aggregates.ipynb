{"cells":[{"cell_type":"markdown","source":["### Spark session configuration\n","This cell sets Spark session settings to enable _Verti-Parquet_ and _Optimize on Write_. More details about _Verti-Parquet_ and _Optimize on Write_ in tutorial document."],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"9a383c91-4963-41da-8822-04679a11924c"},{"cell_type":"code","source":["# Copyright (c) Microsoft Corporation.\n","# Licensed under the MIT License.\n","\n","spark.conf.set(\"spark.sql.parquet.vorder.enabled\", \"true\")\n","spark.conf.set(\"spark.microsoft.delta.optimizeWrite.enabled\", \"true\")\n","spark.conf.set(\"spark.microsoft.delta.optimizeWrite.binSize\", \"1073741824\")"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":-1,"statement_ids":[],"state":"session_starting","livy_statement_state":null,"session_id":null,"normalized_state":"session_starting","queued_time":"2025-12-14T20:57:46.4009996Z","session_start_time":"2025-12-14T20:57:46.4019802Z","execution_start_time":null,"execution_finish_time":null,"parent_msg_id":"c9d61329-12d4-46cd-8e31-a8a140436f9d"},"text/plain":"StatementMeta(, , -1, SessionStarting, , SessionStarting)"},"metadata":{}}],"execution_count":1,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"e71bcd10-4899-478a-acb3-48a719709bdd"},{"cell_type":"markdown","source":["#### Approach #1 - sale_by_date_city\n","In this cell, you are creating three different Spark dataframes, each referencing an existing delta table."],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"26a480b9-5500-41e7-b78e-c92dca6d4d36"},{"cell_type":"code","source":["# SCRIPT DE RESGATE: GERA AS DUAS TABELAS AGREGADAS (GOLD) DE UMA VEZ\n","from pyspark.sql.functions import col, sum as _sum\n","\n","# --- PREPARAÇÃO: LER AS TABELAS BASE (SILVER) ---\n","# Usando os nomes curtos que a gente já consertei\n","fact_sale = spark.read.table(\"fact_sale\")\n","dim_date = spark.read.table(\"dimension_date\")\n","dim_city = spark.read.table(\"dimension_city\")\n","dim_employee = spark.read.table(\"dimension_employee\")\n","\n","print(\"1. Tabelas base lidas com sucesso...\")"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"94c2ed8c-101a-4db8-8c88-e30ae171298d"},{"cell_type":"code","source":["# --- PARTE 1: AGGREGATE SALE BY CITY ---\n","# Join e Agrupamento direto em Python \n","df_city_agg = fact_sale.join(dim_date, fact_sale.InvoiceDateKey == dim_date.Date) \\\n","                       .join(dim_city, fact_sale.CityKey == dim_city.CityKey) \\\n","                       .groupBy(dim_date.Date, dim_date.CalendarMonthLabel, dim_date.CalendarYear, \n","                                dim_city.City, dim_city.StateProvince, dim_city.SalesTerritory) \\\n","                       .agg(\n","                           _sum(fact_sale.TotalExcludingTax).alias(\"SumOfTotalExcludingTax\"),\n","                           _sum(fact_sale.TaxAmount).alias(\"SumOfTaxAmount\"),\n","                           _sum(fact_sale.TotalIncludingTax).alias(\"SumOfTotalIncludingTax\"),\n","                           _sum(fact_sale.Profit).alias(\"SumOfProfit\")\n","                       )\n","\n","# Salvar a tabela final\n","df_city_agg.write.mode(\"overwrite\").format(\"delta\").option(\"overwriteSchema\", \"true\").saveAsTable(\"aggregate_sale_by_date_city\")\n","print(\"Tabela 1 Criada: aggregate_sale_by_date_city\")"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":4,"statement_ids":[4],"state":"finished","livy_statement_state":"available","session_id":"3e00dee1-43b1-4421-a195-c45da55afc64","normalized_state":"finished","queued_time":"2025-12-14T21:02:24.569375Z","session_start_time":null,"execution_start_time":"2025-12-14T21:02:24.5704086Z","execution_finish_time":"2025-12-14T21:02:24.9806313Z","parent_msg_id":"2b62789c-f10c-452f-bf6c-85c04432cf0a"},"text/plain":"StatementMeta(, 3e00dee1-43b1-4421-a195-c45da55afc64, 4, Finished, Available, Finished)"},"metadata":{}},{"output_type":"error","ename":"SyntaxError","evalue":"incomplete input (413541650.py, line 1)","traceback":["\u001b[0;36m  Cell \u001b[0;32mIn[11], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    \"\"\"\"\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m incomplete input\n"]}],"execution_count":2,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"7092d68b-3735-408a-a230-0abf05c64032"},{"cell_type":"markdown","source":["In this cell, you are joining these tables using the dataframes created earlier, doing group by to generate aggregation, renaming few of the columns and finally writing it as delta table in the _Tables_ section of the lakehouse."],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"43f9e7e5-8bcd-4c90-ae85-818df8944023"},{"cell_type":"markdown","source":["#### Approach #2 - sale_by_date_employee\n","In this cell, you are creating a temporary Spark view by joining 3 tables, doing group by to generate aggregation, renaming few of the columns. "],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"85fbd2ae-e5a6-4f46-8763-41735210f260"},{"cell_type":"code","source":["# --- PARTE 2: AGGREGATE SALE BY EMPLOYEE ---\n","# Fazendo o Join e Agrupamento direto\n","df_emp_agg = fact_sale.join(dim_date, fact_sale.InvoiceDateKey == dim_date.Date) \\\n","                      .join(dim_employee, fact_sale.SalespersonKey == dim_employee.EmployeeKey) \\\n","                      .groupBy(dim_date.Date, dim_date.CalendarMonthLabel, dim_date.CalendarYear, \n","                               dim_employee.PreferredName, dim_employee.Employee) \\\n","                      .agg(\n","                           _sum(fact_sale.TotalExcludingTax).alias(\"SumOfTotalExcludingTax\"),\n","                           _sum(fact_sale.TaxAmount).alias(\"SumOfTaxAmount\"),\n","                           _sum(fact_sale.TotalIncludingTax).alias(\"SumOfTotalIncludingTax\"),\n","                           _sum(fact_sale.Profit).alias(\"SumOfProfit\")\n","                       )\n","\n","# Salvar a tabela final\n","df_emp_agg.write.mode(\"overwrite\").format(\"delta\").option(\"overwriteSchema\", \"true\").saveAsTable(\"aggregate_sale_by_date_employee\")\n","print(\"Tabela 2 Criada: aggregate_sale_by_date_employee\")"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"15bc61f9-e54b-4ddb-a83a-fc01fd7be31f"},{"cell_type":"code","source":["print(\"FIM DO ESTRESSE.\")"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":-1,"statement_ids":null,"state":"waiting","livy_statement_state":null,"session_id":null,"normalized_state":"waiting","queued_time":"2025-12-14T20:57:46.4192346Z","session_start_time":null,"execution_start_time":null,"execution_finish_time":null,"parent_msg_id":"04a899e2-9916-41cd-9369-e4679964544b"},"text/plain":"StatementMeta(, , -1, Waiting, , Waiting)"},"metadata":{}}],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"},"collapsed":false},"id":"6cf12da1-2b03-4b8a-b455-086e2e6ee574"},{"cell_type":"markdown","source":["In this cell, you are reading from the temporary Spark view created in the previous cell and and finally writing it as delta table in the _Tables_ section of the lakehouse."],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"510d2915-a72c-49bc-bbb0-4e288a37efa5"}],"metadata":{"language_info":{"name":"python"},"kernelspec":{"name":"synapse_pyspark","language":"Python","display_name":"Synapse PySpark"},"widgets":{},"kernel_info":{"name":"synapse_pyspark"},"notebook_environment":{},"microsoft":{"language":"python","language_group":"synapse_pyspark","ms_spell_check":{"ms_spell_check_language":"en"}},"nteract":{"version":"nteract-front-end@1.0.0"},"synapse_widget":{"version":"0.1","state":{}},"save_output":true,"spark_compute":{"compute_id":"/trident/default","session_options":{"enableDebugMode":false,"conf":{"spark.synapse.nbs.session.timeout":"1200000"}}},"dependencies":{"lakehouse":{"known_lakehouses":[{"id":"f53c3241-a4e5-438d-b584-67cf3da10001"}],"default_lakehouse":"f53c3241-a4e5-438d-b584-67cf3da10001","default_lakehouse_name":"wwilakehouse","default_lakehouse_workspace_id":"203390f7-b50d-44b6-b3f6-edd10cd51a04"}}},"nbformat":4,"nbformat_minor":5}
